# Anal√Ωza: S√©mantick√© vyhled√°v√°n√≠ v textov√Ωch dokumentech

## üìã Shrnut√≠

**Odpovƒõƒè: ANO, je mo≈æn√© p≈ôidat s√©mantick√© vyhled√°v√°n√≠ pro PDF, Markdown a textov√© soubory do SmartScanu.**

---

## üîç Zji≈°tƒõn√≠ o SmartScan SDK

### Souƒçasn√Ω stav SDK:
- ‚ùå **Nepodporuje text embeddings** - pouze image embeddings
- ‚úÖ **CLIP model** - dual-modal (text-to-image search), ale negeneruje pure text embeddings
- ‚ö†Ô∏è **TEXT_ENCODER model typ existuje** v `constants/Models.kt:10` - infrastruktura je p≈ôipraven√°
- **Z√°vƒõr:** Mus√≠me p≈ôidat separ√°tn√≠ text embedding solution

### Podporovan√© modely v SmartScan SDK:
```kotlin
// constants/Models.kt
SmartScanModelType.FACE           // Facial recognition
SmartScanModelType.OBJECTS        // Object detection
SmartScanModelType.IMAGE_ENCODER  // Image embeddings (CLIP)
SmartScanModelType.TEXT_ENCODER   // Text encoder (CLIP, pro text-to-image)
```

---

## ‚úÖ Technick√° proveditelnost

| Komponenta | ≈òe≈°en√≠ | Kompatibilita | Velikost |
|-----------|---------|---------------|----------|
| **Text Embeddings** | all-MiniLM-L6-v2 + ONNX Runtime | ‚úÖ Kompatibiln√≠ s existuj√≠c√≠m stackem | 22 MB |
| **PDF Parsing** | PdfBox-Android (TomRoush fork) | ‚úÖ Pure Java, F-Droid friendly | ~15 MB |
| **Markdown Parsing** | CommonMark-Java / Markwon | ‚úÖ Zero dependencies | ~1 MB |
| **Indexing** | File-based (konzistentn√≠ s images) | ‚úÖ Stejn√Ω pattern jako v1.1.3 | N/A |
| **Search** | Cosine similarity | ‚úÖ Ji≈æ implementov√°no pro images | N/A |

---

## üéØ Doporuƒçen√© ≈ôe≈°en√≠

### Architektura:

```
Text Documents (PDF/MD/TXT)
        ‚Üì
   Parser Layer
   ‚îú‚îÄ‚îÄ PdfBox-Android (PDF)
   ‚îú‚îÄ‚îÄ CommonMark-Java (MD)
   ‚îî‚îÄ‚îÄ File.readText() (TXT)
        ‚Üì
   Chunking Service
   (512 tokens, 15% overlap)
        ‚Üì
   all-MiniLM-L6-v2 ONNX Model
        ‚Üì
   384-dim Embeddings
        ‚Üì
   File-based Index (JSON)
        ‚Üì
   Cosine Similarity Search
```

### Knihovny k p≈ôid√°n√≠:

```gradle
// build.gradle.kts
dependencies {
    // Text embeddings - Sentence Transformers pro Android
    implementation("com.github.shubham0204:Sentence-Embeddings-Android:1.x.x")

    // PDF parsing - Apache PDFBox fork pro Android
    implementation("com.tom-roush:pdfbox-android:2.0.27.0")

    // Markdown parsing
    implementation("io.noties.markwon:core:4.6.2")
    // nebo
    implementation("org.commonmark:commonmark:0.21.0")
}
```

---

## üí° Implementaƒçn√≠ pl√°n (high-level)

### **F√°ze 1: Infrastruktura (Foundation)**
1. ‚úÖ P≈ôidat text embedding dependencies do `build.gradle.kts`
2. ‚úÖ St√°hnout/integrovat all-MiniLM-L6-v2 ONNX model
3. ‚úÖ Roz≈°√≠≈ôit `SmartScanModelType` enum o `TEXT_DOCUMENT_ENCODER`
4. ‚úÖ Vytvo≈ôit data model:
   - `TextDocument` entity (Room DB metadata)
   - `DocumentChunk` data class
   - `DocumentEmbeddingIndex` (file-based storage)

### **F√°ze 2: Document Processing**
5. ‚úÖ Implementovat parsery:
   - `PdfParser` (PdfBox-Android)
   - `MarkdownParser` (CommonMark-Java)
   - `TxtParser` (plain text)
6. ‚úÖ Document chunking service:
   - Semantic chunking (split na vƒõty ‚Üí group)
   - 512 tokens per chunk, 15% overlap
   - Metadata tracking (file path, page, offset)
7. ‚úÖ Text embedding extraction:
   - `TextEmbeddingExtractor` wrapper
   - Batch processing (10 chunks at once)
   - Memory management
8. ‚úÖ Background worker:
   - `DocumentIndexWorker` (WorkManager)
   - Foreground service s notifikac√≠
   - Progress tracking

### **F√°ze 3: Search & UI**
9. ‚úÖ Roz≈°√≠≈ôit search screen:
   - Unified search (images + documents)
   - Document result cards
   - Relevance scoring (cosine similarity)
10. ‚úÖ Document viewer UI:
    - PDF viewer (fragment)
    - Markdown renderer (Markwon)
    - Highlight matched chunks
11. ‚úÖ Settings:
    - Document indexing preferences
    - File type filters
    - Auto-refresh intervals

---

## üîß Technick√© detaily

### 1. Text Embedding Model

**Doporuƒçen√Ω model: all-MiniLM-L6-v2**

- **Zdroj:** [HuggingFace - onnx-models/all-MiniLM-L6-v2-onnx](https://huggingface.co/onnx-models/all-MiniLM-L6-v2-onnx)
- **Velikost:** 22 MB (ONNX), 5 MB (tokenizer native lib)
- **Embedding dimension:** 384
- **Performance:** ~60ms per chunk (512 tokens) na mid-range Android
- **Jazyk:** English (pro multilingual pou≈æ√≠t `paraphrase-multilingual-MiniLM-L12-v2`)

**Implementace (pseudo-code):**
```kotlin
// Inicializace
val sentenceEmbedding = SentenceEmbedding(
    modelFile = context.filesDir.resolve("models/text_encoder.onnx"),
    tokenizerFile = context.filesDir.resolve("models/tokenizer.json"),
    useTokenTypeIds = true,
    outputTensorName = "last_hidden_state",
    useFP16 = true,      // 2x men≈°√≠ storage, <1% quality loss
    useXNNPack = true    // CPU optimization pro ARM
)

// Z√≠sk√°n√≠ embeddings
val embedding: FloatArray = sentenceEmbedding.encode("V√°≈° text")
// Output: [384] float array
```

**Alternativn√≠ modely:**
- **snowflake-arctic-embed-s:** Vy≈°≈°√≠ kvalita, pomalej≈°√≠ (~100 MB)
- **bge-small-en:** Alternativa k MiniLM (33 MB)
- **model2vec:** Ultra-lightweight (5 MB), ni≈æ≈°√≠ kvalita

---

### 2. PDF Parsing

**Knihovna: PdfBox-Android**

- **Repo:** [TomRoush/PdfBox-Android](https://github.com/TomRoush/PdfBox-Android)
- **Licence:** Apache 2.0 (F-Droid compatible)
- **API:** PDDocument, PDFTextStripper

**Best practices:**
```kotlin
// Memory-efficient page-by-page extraction
fun extractPdfText(uri: Uri): List<String> {
    val inputStream = contentResolver.openInputStream(uri)
    val document = PDDocument.load(inputStream)
    val stripper = PDFTextStripper()
    val pages = mutableListOf<String>()

    for (page in 1..document.numberOfPages) {
        stripper.startPage = page
        stripper.endPage = page
        val text = stripper.getText(document)
        pages.add(text)
    }

    document.close()
    return pages
}
```

**Performance pozn√°mky:**
- ‚ö†Ô∏è Kotlin vs Java: ~2s rozd√≠l v testu (PDFBox 2.0.12)
- ‚úÖ Extrahuj text po str√°nk√°ch, ne cel√Ω dokument najednou
- ‚úÖ Close PDDocument po pou≈æit√≠ (nen√≠ thread-safe)

**Alternativy:**
- **iText:** Komerƒçn√≠ licence (AGPL pro open-source)
- **PdfiumAndroid:** Nativn√≠, rychlej≈°√≠, slo≈æitƒõj≈°√≠ API

---

### 3. Markdown Parsing

**Doporuƒçen√© knihovny:**

**Option A: Markwon** (Android-native)
- **Repo:** [noties/Markwon](https://github.com/noties/Markwon)
- **Features:** CommonMark spec, HTML support, syntax highlight
- **API Level:** Min 19
- **Use case:** Rendering + text extraction

**Option B: CommonMark-Java** (standalone)
- **Repo:** [commonmark/commonmark-java](https://github.com/commonmark/commonmark-java)
- **Performance:** 10-20x rychlej≈°√≠ ne≈æ pegdown
- **API:** AST-based, extensible
- **Use case:** Pure text extraction

**Implementace (CommonMark-Java):**
```kotlin
fun extractMarkdownText(markdown: String): String {
    val parser = Parser.builder().build()
    val document = parser.parse(markdown)
    val textBuilder = StringBuilder()

    document.accept(object : AbstractVisitor() {
        override fun visit(text: Text) {
            textBuilder.append(text.literal).append(" ")
        }
        override fun visit(heading: Heading) {
            // Preserve headings for semantic structure
            textBuilder.append("\n\n")
            visitChildren(heading)
            textBuilder.append("\n\n")
        }
    })

    return textBuilder.toString()
}
```

**Plain TXT:**
```kotlin
fun extractPlainText(file: File): String {
    return file.readText(Charset.forName("UTF-8"))
}
```

---

### 4. Chunking Strategie

**Doporuƒçen√° metoda: Semantic Chunking**

**Parametry:**
- **Chunk size:** 512 tokens (optimal pro all-MiniLM-L6-v2)
- **Overlap:** 15-20% (p≈ôedejde boundary loss)
- **Granularita:** Split na vƒõty ‚Üí group po 3-5 vƒõt√°ch

**Proƒç overlap?**
- Informace roz≈ô√≠znut√° mezi chunky by byla ztracena
- 15% overlap = posledn√≠ ~75 token≈Ø z p≈ôedchoz√≠ho chunku

**Implementace (pseudo-code):**
```kotlin
data class DocumentChunk(
    val id: String,              // "doc1_chunk0"
    val text: String,            // P≈Øvodn√≠ text
    val embedding: FloatArray,   // 384-dim embedding
    val metadata: ChunkMetadata
)

data class ChunkMetadata(
    val filePath: String,
    val pageNumber: Int?,        // Pro PDF
    val charOffset: Int,         // Start position v dokumentu
    val chunkIndex: Int
)

fun chunkDocument(
    text: String,
    maxTokens: Int = 512,
    overlapPercent: Float = 0.15f
): List<DocumentChunk> {
    val sentences = text.splitToSentences()  // NLTK-style
    val chunks = mutableListOf<DocumentChunk>()

    var currentChunk = StringBuilder()
    var currentTokens = 0
    var charOffset = 0

    for (sentence in sentences) {
        val sentenceTokens = tokenizer.encode(sentence).size

        if (currentTokens + sentenceTokens > maxTokens) {
            // Save current chunk
            chunks.add(
                DocumentChunk(
                    id = "doc_chunk${chunks.size}",
                    text = currentChunk.toString(),
                    embedding = embedModel.encode(currentChunk.toString()),
                    metadata = ChunkMetadata(
                        filePath = filePath,
                        pageNumber = currentPage,
                        charOffset = charOffset,
                        chunkIndex = chunks.size
                    )
                )
            )

            // Apply overlap: keep last N tokens
            val overlapSize = (maxTokens * overlapPercent).toInt()
            val overlapText = getLastNTokens(currentChunk.toString(), overlapSize)
            currentChunk = StringBuilder(overlapText)
            currentTokens = overlapSize
        }

        currentChunk.append(sentence).append(" ")
        currentTokens += sentenceTokens
    }

    // Save last chunk
    if (currentChunk.isNotEmpty()) {
        chunks.add(createChunk(currentChunk.toString()))
    }

    return chunks
}
```

**Chunking guidelines podle typu:**

| Document Type | Chunk Size | Overlap | Split Strategy |
|--------------|-----------|---------|----------------|
| PDF (technical) | 512-1024 tokens | 15-25% | Str√°nky ‚Üí odstavce ‚Üí vƒõty |
| Markdown | 256-512 tokens | 10-20% | Headings ‚Üí odstavce ‚Üí vƒõty |
| Plain TXT | 256-512 tokens | 10-20% | Odstavce ‚Üí vƒõty |
| Code snippets | 100-300 tokens | 20% | Function/class scope |

---

### 5. Indexing & Storage

**File-based index (konzistentn√≠ s image embeddings od v1.1.3):**

```json
{
  "version": "1.0.0",
  "documentCount": 42,
  "chunks": [
    {
      "id": "doc1_chunk0",
      "text": "This is the first chunk of document 1...",
      "embedding": [0.123, -0.456, 0.789, ...],  // 384 floats
      "metadata": {
        "filePath": "/storage/emulated/0/Documents/report.pdf",
        "fileName": "report.pdf",
        "fileType": "pdf",
        "pageNumber": 1,
        "charOffset": 0,
        "chunkIndex": 0,
        "timestamp": 1704067200000
      }
    }
  ]
}
```

**Storage location:**
```
context.filesDir/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ text_encoder.onnx       (22 MB)
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.json          (5 MB)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ indexes/
‚îÇ   ‚îú‚îÄ‚îÄ documents_index.json    (embeddings + metadata)
‚îÇ   ‚îî‚îÄ‚îÄ documents_metadata.db   (Room DB - scan history, jobs)
```

**Room DB schema (pouze metadata):**
```kotlin
@Entity(tableName = "text_documents")
data class TextDocument(
    @PrimaryKey val id: String,
    val filePath: String,
    val fileName: String,
    val fileType: String,      // "pdf", "md", "txt"
    val fileSize: Long,
    val chunkCount: Int,
    val indexedAt: Long,
    val lastModified: Long
)

@Entity(tableName = "document_scans")
data class DocumentScan(
    @PrimaryKey(autoGenerate = true) val id: Long = 0,
    val scanDate: Long,
    val documentsFound: Int,
    val documentsIndexed: Int,
    val duration: Long
)
```

---

### 6. Search Implementation

**Cosine similarity (ji≈æ existuje pro images):**
```kotlin
fun cosineSimilarity(a: FloatArray, b: FloatArray): Float {
    require(a.size == b.size) { "Vectors must have same dimension" }

    var dotProduct = 0.0
    var magnitudeA = 0.0
    var magnitudeB = 0.0

    for (i in a.indices) {
        dotProduct += a[i] * b[i]
        magnitudeA += a[i] * a[i]
        magnitudeB += b[i] * b[i]
    }

    magnitudeA = sqrt(magnitudeA)
    magnitudeB = sqrt(magnitudeB)

    return (dotProduct / (magnitudeA * magnitudeB)).toFloat()
}
```

**Search pipeline:**
```kotlin
suspend fun searchDocuments(
    query: String,
    topK: Int = 10,
    minSimilarity: Float = 0.5f
): List<SearchResult> = withContext(Dispatchers.Default) {
    // 1. Generate query embedding
    val queryEmbedding = textEmbedModel.encode(query)

    // 2. Load document index
    val index = loadDocumentIndex()

    // 3. Compute similarities
    val results = index.chunks
        .asSequence()
        .map { chunk ->
            SearchResult(
                chunk = chunk,
                similarity = cosineSimilarity(queryEmbedding, chunk.embedding)
            )
        }
        .filter { it.similarity >= minSimilarity }
        .sortedByDescending { it.similarity }
        .take(topK)
        .toList()

    return@withContext results
}
```

**Unified search (images + documents):**
```kotlin
data class UnifiedSearchResult(
    val type: ResultType,      // IMAGE, DOCUMENT
    val score: Float,
    val data: Any              // ImageResult or DocumentResult
)

suspend fun unifiedSearch(query: String): List<UnifiedSearchResult> {
    // Parallel search
    val imageResults = async { searchImages(query) }
    val docResults = async { searchDocuments(query) }

    // Merge & sort by relevance
    return (imageResults.await() + docResults.await())
        .sortedByDescending { it.score }
}
```

---

## üìä Performance & Optimizace

### Memory Management

**Model loading:**
```kotlin
// Lazy initialization
private val textEmbedModel: SentenceEmbedding by lazy {
    SentenceEmbedding(
        modelFile = modelPath,
        tokenizerFile = tokenizerPath,
        useFP16 = true,        // 2x men≈°√≠ storage
        useXNNPack = true      // CPU optimization
    )
}

// Clear po pou≈æit√≠
fun cleanup() {
    textEmbedModel.close()
}
```

**Batch processing:**
```kotlin
// Process documents in batches
suspend fun indexDocuments(documents: List<File>) {
    val batchSize = 10
    documents.chunked(batchSize).forEach { batch ->
        batch.forEach { doc ->
            val chunks = parseAndChunk(doc)
            chunks.chunked(10).forEach { chunkBatch ->
                // Embed 10 chunks at once
                val embeddings = textEmbedModel.encodeBatch(
                    chunkBatch.map { it.text }
                )
                saveEmbeddings(chunkBatch, embeddings)
            }
        }

        // Clear intermediate buffers
        System.gc()
    }
}
```

### Inference Optimizations

**1. FP16 (Half-precision):**
- Storage: 2x men≈°√≠
- Quality loss: <1%
- Enable: `useFP16 = true`

**2. XNNPack (CPU optimization):**
- Speedup: 1.4-3x na ARM CPUs
- Enable: `useXNNPack = true`

**3. Quantization (INT8):**
- Storage: 4x men≈°√≠
- Quality loss: ~5%
- Vy≈æaduje custom ONNX model

**Benchmark (Samsung M13, 4GB RAM):**
```
Model: all-MiniLM-L6-v2
Input: 128 tokens

Baseline (FP32):         ~90ms
FP16 + XNNPack:         ~60ms
INT8 quantized:         ~45ms
```

---

## ‚ö†Ô∏è D≈Øle≈æit√© pozn√°mky

### Model Size Impact

| Komponenta | Velikost | Pozn√°mka |
|-----------|----------|----------|
| St√°vaj√≠c√≠ CLIP (IMAGE_ENCODER) | ~75 MB | Ji≈æ v projektu |
| St√°vaj√≠c√≠ CLIP (TEXT_ENCODER) | ~75 MB | Ji≈æ v projektu |
| **Nov√Ω text model** | **+22 MB** | all-MiniLM-L6-v2 |
| Tokenizer (Rust native lib) | +5 MB | HuggingFace tokenizers |
| **Celkem** | **~177 MB** | Akceptovateln√© pro on-device |

### Performance Expectations

**Indexov√°n√≠ (1000-page PDF):**
- Parsing: ~30s (PdfBox-Android)
- Chunking: ~5s (512 tokens/chunk ‚Üí ~2000 chunks)
- Embedding extraction: ~2 min (60ms √ó 2000 chunks)
- **Total:** ~2.5 min (background WorkManager job)

**Search (10k chunks index):**
- Query embedding: ~60ms
- Similarity computation: ~50ms (brute-force)
- **Total:** ~110ms per query

**Optimalizace pro vƒõt≈°√≠ scale:**
- FAISS index (ANN search): ~5-10ms pro 100k chunks
- Vy≈æaduje native compile (slo≈æitƒõj≈°√≠ F-Droid build)

### F-Droid Compatibility

| Knihovna | Licence | F-Droid | Pozn√°mka |
|----------|---------|---------|----------|
| Sentence-Embeddings-Android | Apache 2.0 | ‚úÖ | Open-source, reprodukovateln√Ω build |
| PdfBox-Android | Apache 2.0 | ‚úÖ | Pure Java, zero native deps |
| CommonMark-Java | BSD 2-Clause | ‚úÖ | Zero dependencies |
| ONNX Runtime | MIT | ‚úÖ | Maven Central artifacts |
| HuggingFace Tokenizers | Apache 2.0 | ‚úÖ | Rust ‚Üí .so prebuilt |

**‚ö†Ô∏è Pozn√°mka k FAISS:**
- ‚ùå Vy≈æaduje NDK build (native C++)
- Komplikuje F-Droid reproducible builds
- Doporuƒçen√≠: Start s brute-force, p≈ôidej FAISS pozdƒõji pokud nutn√©

---

## üîó Zdroje & Reference

### Implementace

**Text Embeddings:**
- [Sentence-Embeddings-Android GitHub](https://github.com/shubham0204/Sentence-Embeddings-Android)
- [ProAndroidDev ƒçl√°nek](https://proandroiddev.com/from-python-to-android-hf-sentence-transformers-embeddings-1ecea0ce94d8)
- [ONNX Runtime Android](https://onnxruntime.ai/docs/get-started/with-java.html)

**PDF Parsing:**
- [PdfBox-Android GitHub](https://github.com/TomRoush/PdfBox-Android)
- [Apache PDFBox Documentation](https://pdfbox.apache.org/)

**Markdown Parsing:**
- [Markwon GitHub](https://github.com/noties/Markwon)
- [CommonMark-Java GitHub](https://github.com/commonmark/commonmark-java)
- [CommonMark Spec](https://commonmark.org/)

**ML Models:**
- [all-MiniLM-L6-v2 (ONNX)](https://huggingface.co/onnx-models/all-MiniLM-L6-v2-onnx)
- [Sentence Transformers Hub](https://huggingface.co/sentence-transformers)
- [ONNX Model Zoo](https://github.com/onnx/models)

### Best Practices

**Chunking Strategies:**
- [Pinecone - Chunking Guide](https://www.pinecone.io/learn/chunking-strategies/)
- [Stack Overflow - RAG Chunking](https://stackoverflow.blog/2024/12/27/breaking-up-is-hard-to-do-chunking-in-rag-applications/)
- [Chroma Research - Evaluating Chunking](https://research.trychroma.com/evaluating-chunking)
- [Late Chunking Paper (2024)](https://arxiv.org/html/2409.04701v3)

**Semantic Search:**
- [OpenAI - Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [Google - Semantic Search Best Practices](https://cloud.google.com/blog/topics/developers-practitioners/meet-ais-multitool-vector-embeddings)

---

## üöÄ Dal≈°√≠ kroky

### Mo≈ænosti pokraƒçov√°n√≠:

**A) Detailn√≠ implementaƒçn√≠ pl√°n**
- Konkr√©tn√≠ TODO items s file paths
- Code snippets pro ka≈ædou komponentu
- Testovac√≠ strategie

**B) Datab√°zov√Ω schema design**
- Room entities + DAOs
- Migration strategy z v1.1.3
- Index file format

**C) Proof-of-concept**
- Integrace Sentence-Embeddings-Android
- Minim√°ln√≠ PDF parsing demo
- Search prototype

**D) Architecture review**
- Dopad na existuj√≠c√≠ codebase
- Refactoring pot≈ôeby
- Backward compatibility

---

**Datum anal√Ωzy:** 2025-10-27
**SmartScan verze:** v1.1.3
**Analyzov√°no pro:** mist≈ôe Jardo

---

## üìù Pozn√°mky k implementaci

### Edge Cases

**1. Multi-language documents:**
- all-MiniLM-L6-v2 = English only
- Pro multilingual: `paraphrase-multilingual-MiniLM-L12-v2` (118 MB)
- Detect language ‚Üí use appropriate model

**2. PDF s obr√°zky/tabulkami:**
- PdfBox extracts text v reading order
- Obr√°zky/tabulky = mezery v textu
- Mo≈ænost: OCR integration (Tesseract-Android)

**3. Markdown code blocks:**
- Skip nebo preserve jako single chunk?
- Syntax highlighting metadata
- Language detection

**4. Large documents:**
- Streaming parsing (don't load entire file)
- Progressive indexing (save chunks incrementally)
- Memory pressure monitoring

### Testing Strategy

**Unit tests:**
```kotlin
// Chunking logic
@Test
fun `test semantic chunking with overlap`() { ... }

// Similarity computation
@Test
fun `test cosine similarity calculation`() { ... }

// Parser integration
@Test
fun `test PDF text extraction`() { ... }
```

**Integration tests:**
```kotlin
// End-to-end indexing
@Test
fun `test document indexing pipeline`() { ... }

// Search accuracy
@Test
fun `test search returns relevant results`() { ... }
```

**Performance tests:**
```kotlin
// Benchmark chunking
@Test
fun `benchmark chunk 1000-page PDF`() { ... }

// Benchmark search
@Test
fun `benchmark search in 10k chunks`() { ... }
```

### Migration Path

**Pro existuj√≠c√≠ SmartScan users:**

1. **Opt-in feature** (Settings toggle)
2. **Background migration** (scan documents on first launch)
3. **Progress notification** (jako u image indexing)
4. **Fallback** (graceful degradation pokud modely chyb√≠)

---

## ‚úÖ Z√°vƒõr

**SmartScan m≈Ø≈æe b√Ωt roz≈°√≠≈ôen o s√©mantick√© vyhled√°v√°n√≠ v dokumentech:**

- ‚úÖ Technicky provediteln√© (100%)
- ‚úÖ F-Droid compatible stack
- ‚úÖ Konzistentn√≠ s existuj√≠c√≠ architekturou
- ‚úÖ Reasonable performance (on-device)
- ‚úÖ Moderate storage impact (+27 MB)

**Doporuƒçen√≠:**
- Start s all-MiniLM-L6-v2 (optimal kvalita/rychlost)
- File-based embeddings storage (konzistence)
- Background WorkManager indexing
- Opt-in feature v Settings

**Rizika:**
- Model download size (+27 MB)
- Indexing time (2-3 min per 1000 pages)
- English-only support (initial version)
- Memory usage (batch processing kritick√Ω)

**Celkov√© hodnocen√≠:** üü¢ **Doporuƒçeno k implementaci**
