# Anal√Ωza: S√©mantick√© vyhled√°v√°n√≠ v textov√Ωch dokumentech

## üìã Shrnut√≠

**Odpovƒõƒè: ANO, je mo≈æn√© p≈ôidat s√©mantick√© vyhled√°v√°n√≠ pro PDF, Markdown a textov√© soubory do SmartScanu.**

---

## ‚úÖ DETAILN√ç TODO PRO IMPLEMENTACI

### üéØ F√ÅZE 1: INFRASTRUKTURA & DEPENDENCIES (Foundation)

#### 1.1 P≈ôid√°n√≠ dependencies
- [ ] **P≈ôidat knihovny do `app/build.gradle.kts`:**
  ```gradle
  // Text embeddings
  implementation("com.github.shubham0204:Sentence-Embeddings-Android:1.0.0")

  // PDF parsing
  implementation("com.tom-roush:pdfbox-android:2.0.27.0")

  // Markdown parsing
  implementation("org.commonmark:commonmark:0.21.0")
  ```
- [ ] **Sync Gradle a ovƒõ≈ôit build:** `./gradlew assembleDebug`
- [ ] **Commit:** `üîß config: P≈ôid√°n√≠ dependencies pro document search`

#### 1.2 Model type extensions
- [ ] **Vytvo≈ôit `constants/DocumentModels.kt`:**
  - Enum `DocumentType` (PDF, MARKDOWN, TXT)
  - `DocumentModelInfo` data class
  - Konstanta `TEXT_DOCUMENT_MODEL_PATH`
- [ ] **Roz≈°√≠≈ôit `data/SmartScanModelType.kt`** (pokud existuje jako enum):
  - P≈ôidat `TEXT_DOCUMENT_ENCODER` typ
- [ ] **Commit:** `‚ú® feat: Model types pro document embeddings`

#### 1.3 Data models (Room DB + File-based)
- [ ] **Vytvo≈ôit `data/documents/TextDocument.kt`:**
  ```kotlin
  @Entity(tableName = "text_documents")
  data class TextDocument(
      @PrimaryKey val id: String,
      val filePath: String,
      val fileName: String,
      val fileType: String,
      val fileSize: Long,
      val chunkCount: Int,
      val indexedAt: Long,
      val lastModified: Long
  )
  ```
- [ ] **Vytvo≈ôit `data/documents/DocumentChunk.kt`:**
  ```kotlin
  data class DocumentChunk(
      val id: String,
      val text: String,
      val embedding: FloatArray,
      val metadata: ChunkMetadata
  )

  data class ChunkMetadata(
      val filePath: String,
      val fileName: String,
      val fileType: String,
      val pageNumber: Int?,
      val charOffset: Int,
      val chunkIndex: Int,
      val timestamp: Long
  )
  ```
- [ ] **Vytvo≈ôit `data/documents/DocumentScan.kt`:**
  ```kotlin
  @Entity(tableName = "document_scans")
  data class DocumentScan(
      @PrimaryKey(autoGenerate = true) val id: Long = 0,
      val scanDate: Long,
      val documentsFound: Int,
      val documentsIndexed: Int,
      val failedDocuments: Int,
      val duration: Long
  )
  ```
- [ ] **Vytvo≈ôit `data/documents/DocumentEmbeddingIndex.kt`:**
  ```kotlin
  @Serializable
  data class DocumentEmbeddingIndex(
      val version: String = "1.0.0",
      val documentCount: Int,
      val chunkCount: Int,
      val lastUpdated: Long,
      val chunks: List<DocumentChunk>
  )
  ```
- [ ] **Commit:** `üóÑÔ∏è feat: Data models pro document indexing`

#### 1.4 Database setup
- [ ] **Vytvo≈ôit `data/documents/DocumentDao.kt`:**
  - `@Dao` interface s CRUD operacemi
  - `insert`, `update`, `delete`, `getAll`, `getByPath`, `getByType`
- [ ] **Vytvo≈ôit `data/documents/DocumentScanDao.kt`:**
  - Historie scan≈Ø
  - `getRecentScans`, `insertScan`
- [ ] **Roz≈°√≠≈ôit `AppDatabase.kt`:**
  - P≈ôidat `TextDocument` a `DocumentScan` entities
  - Vytvo≈ôit migration z aktu√°ln√≠ verze (pravdƒõpodobnƒõ v18 ‚Üí v19)
- [ ] **Vytvo≈ôit migration test:**
  - `androidTest/data/MigrationTest.kt`
  - Ovƒõ≈ôit upgrade z v18 na v19
- [ ] **Commit:** `üóÑÔ∏è feat: Database schema pro documents`

#### 1.5 Model download/import
- [ ] **St√°hnout all-MiniLM-L6-v2 ONNX model:**
  - URL: `https://huggingface.co/onnx-models/all-MiniLM-L6-v2-onnx/resolve/main/model.onnx`
  - Target: `app/src/main/assets/models/text_document_encoder.onnx`
- [ ] **St√°hnout tokenizer:**
  - URL: `https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer.json`
  - Target: `app/src/main/assets/models/tokenizer.json`
- [ ] **Vytvo≈ôit `lib/ModelManager.kt` extension:**
  - `copyTextModelToInternalStorage()`
  - `verifyTextModelExists()`
- [ ] **Test model loading:**
  - Vytvo≈ôit unit test v `test/lib/ModelManagerTest.kt`
- [ ] **Commit:** `üì¶ deps: All-MiniLM-L6-v2 ONNX model + tokenizer`

---

### üîß F√ÅZE 2: DOCUMENT PROCESSING PIPELINE

#### 2.1 Parser Layer
- [ ] **Vytvo≈ôit `lib/parsers/DocumentParser.kt` interface:**
  ```kotlin
  interface DocumentParser {
      suspend fun parseDocument(uri: Uri): ParseResult
  }

  data class ParseResult(
      val text: String,
      val pageCount: Int?,
      val metadata: Map<String, String>
  )
  ```
- [ ] **Implementovat `lib/parsers/PdfParser.kt`:**
  - Pou≈æ√≠t PdfBox-Android (`PDDocument`, `PDFTextStripper`)
  - Page-by-page extraction pro memory efficiency
  - Error handling (corrupted PDFs)
- [ ] **Implementovat `lib/parsers/MarkdownParser.kt`:**
  - CommonMark-Java AST traversal
  - Preserve heading structure
  - Skip/handle code blocks
- [ ] **Implementovat `lib/parsers/TxtParser.kt`:**
  - Simple `File.readText()` s UTF-8 encoding
  - Handle large files (streaming?)
- [ ] **Vytvo≈ôit `lib/parsers/ParserFactory.kt`:**
  - Factory method: `getParser(fileType: DocumentType)`
- [ ] **Unit testy:**
  - `test/lib/parsers/PdfParserTest.kt`
  - `test/lib/parsers/MarkdownParserTest.kt`
  - `test/lib/parsers/TxtParserTest.kt`
  - Test s re√°ln√Ωmi sample soubory v `test/resources/`
- [ ] **Commit:** `‚ú® feat: Document parsers (PDF/MD/TXT)`

#### 2.2 Chunking Service
- [ ] **Vytvo≈ôit `lib/chunking/TextChunker.kt`:**
  ```kotlin
  interface TextChunker {
      fun chunk(
          text: String,
          maxTokens: Int = 512,
          overlapPercent: Float = 0.15f
      ): List<TextChunk>
  }

  data class TextChunk(
      val text: String,
      val startOffset: Int,
      val endOffset: Int,
      val tokenCount: Int
  )
  ```
- [ ] **Implementovat `lib/chunking/SemanticChunker.kt`:**
  - Sentence splitting (naive: `.split(". ")`; advanced: NLTK-style)
  - Token counting (pomoc√≠ tokenizer z model)
  - Overlap logic (keep last N tokens)
  - Handle edge cases (empty chunks, oversized sentences)
- [ ] **Vytvo≈ôit `lib/chunking/TokenCounter.kt`:**
  - Wrapper kolem HuggingFace tokenizer
  - `countTokens(text: String): Int`
  - `encodeToTokens(text: String): List<Int>`
- [ ] **Unit testy:**
  - `test/lib/chunking/SemanticChunkerTest.kt`
  - Test overlap correctness
  - Test token count accuracy
  - Test edge cases (very long sentence, empty text)
- [ ] **Commit:** `‚ú® feat: Semantic text chunking s overlap`

#### 2.3 Text Embedding Extraction
- [ ] **Vytvo≈ôit `lib/embeddings/TextEmbeddingExtractor.kt`:**
  ```kotlin
  class TextEmbeddingExtractor(
      private val context: Context
  ) {
      private val model: SentenceEmbedding by lazy {
          SentenceEmbedding(
              modelFile = getModelPath(),
              tokenizerFile = getTokenizerPath(),
              useFP16 = true,
              useXNNPack = true
          )
      }

      suspend fun extractEmbedding(text: String): FloatArray
      suspend fun extractBatch(texts: List<String>): List<FloatArray>
      fun close()
  }
  ```
- [ ] **Implementovat batch processing:**
  - `extractBatch()` s max batch size (10-20 chunks)
  - Memory monitoring
  - Timeout handling
- [ ] **Error handling:**
  - Model not found exception
  - OOM exception (reduce batch size)
  - Invalid input (empty text)
- [ ] **Unit testy:**
  - `test/lib/embeddings/TextEmbeddingExtractorTest.kt`
  - Mock SentenceEmbedding (Mockk)
  - Test batch processing
  - Test error scenarios
- [ ] **Commit:** `‚ú® feat: Text embedding extraction s batch support`

#### 2.4 Repository Layer
- [ ] **Vytvo≈ôit `data/documents/DocumentRepository.kt`:**
  ```kotlin
  class DocumentRepository(
      private val dao: DocumentDao,
      private val context: Context
  ) {
      suspend fun indexDocument(uri: Uri): Result<TextDocument>
      suspend fun getAllDocuments(): Flow<List<TextDocument>>
      suspend fun getDocumentsByType(type: DocumentType): List<TextDocument>
      suspend fun deleteDocument(id: String)
      suspend fun searchDocuments(query: String, topK: Int = 10): List<SearchResult>
  }
  ```
- [ ] **Implementovat file-based embedding storage:**
  - `saveEmbeddingIndex(index: DocumentEmbeddingIndex)`
  - `loadEmbeddingIndex(): DocumentEmbeddingIndex`
  - Location: `context.filesDir/indexes/documents_index.json`
- [ ] **Implementovat search logic:**
  - Load index
  - Query embedding extraction
  - Cosine similarity computation (reuse z image search)
  - Sort by relevance
  - Filter by minSimilarity threshold
- [ ] **Unit testy:**
  - `test/data/documents/DocumentRepositoryTest.kt`
  - Mock DAO a context
  - Test CRUD operations
  - Test search accuracy
- [ ] **Commit:** `‚ú® feat: Document repository s file-based indexing`

#### 2.5 Background Worker
- [ ] **Vytvo≈ôit `workers/DocumentIndexWorker.kt`:**
  ```kotlin
  class DocumentIndexWorker(
      context: Context,
      params: WorkerParameters
  ) : CoroutineWorker(context, params) {
      override suspend fun doWork(): Result {
          // 1. Scan for documents
          // 2. Filter new/modified
          // 3. Parse ‚Üí Chunk ‚Üí Embed
          // 4. Save to index
          // 5. Update progress notification
      }
  }
  ```
- [ ] **Implementovat foreground service notification:**
  - `createNotificationChannel()`
  - Progress notification s cancel button
  - Update progress: "Indexov√°n√≠ dokument≈Ø... (5/20)"
- [ ] **Implementovat batch processing:**
  - Process 10 documents at a time
  - Clear memory between batches (`System.gc()`)
  - Handle errors (skip corrupted files, log)
- [ ] **Constraints:**
  - Charging preferred (not required)
  - Storage not low
- [ ] **Commit:** `‚ú® feat: Background document indexing worker`

#### 2.6 Document Scan Service
- [ ] **Vytvo≈ôit `services/DocumentScanService.kt`:**
  - Scan specified folders for PDF/MD/TXT
  - Filter by last modified date (skip already indexed)
  - Return list of URIs to index
- [ ] **Implementovat folder picker:**
  - Use SAF (Storage Access Framework)
  - Persist permissions (`takePersistableUriPermission`)
  - Store selected folders v SharedPreferences
- [ ] **Unit testy:**
  - `test/services/DocumentScanServiceTest.kt`
  - Mock ContentResolver
  - Test file filtering logic
- [ ] **Commit:** `‚ú® feat: Document scan service s folder picker`

---

### üé® F√ÅZE 3: UI & SEARCH INTEGRATION

#### 3.1 Settings Screen Extensions
- [ ] **Roz≈°√≠≈ôit `ui/screens/settings/SettingsScreen.kt`:**
  - Section: "Document Search"
  - Toggle: Enable/Disable document search
  - Button: "Select Document Folders"
  - Button: "Re-index Documents"
  - Info: Last scan date, document count
- [ ] **Vytvo≈ôit `ui/screens/settings/DocumentSettingsViewModel.kt`:**
  - State: `documentSearchEnabled`, `selectedFolders`, `lastScanDate`
  - Actions: `toggleDocumentSearch()`, `addFolder()`, `removeFolder()`, `triggerReindex()`
- [ ] **Implementovat folder picker dialog:**
  - Launch SAF folder picker
  - Display selected folders as chips
  - Remove folder action
- [ ] **Commit:** `‚ú® feat: Document search settings UI`

#### 3.2 Search Screen Extensions
- [ ] **Roz≈°√≠≈ôit `ui/screens/search/SearchScreen.kt`:**
  - Tab/Chip filter: "V≈°e" | "Obr√°zky" | "Dokumenty"
  - Document result cards (vedle image results)
  - Unified sort by relevance
- [ ] **Vytvo≈ôit `ui/components/DocumentResultCard.kt`:**
  ```kotlin
  @Composable
  fun DocumentResultCard(
      result: DocumentSearchResult,
      onClick: () -> Unit
  ) {
      // Display: file icon, title, snippet, relevance score
  }
  ```
- [ ] **Roz≈°√≠≈ôit `ui/screens/search/SearchViewModel.kt`:**
  - P≈ôidat `searchDocuments()` flow
  - Merge image + document results
  - Filter by selected type
  - State: `documentResults`, `selectedResultType`
- [ ] **Commit:** `‚ú® feat: Unified search UI (images + documents)`

#### 3.3 Document Viewer
- [ ] **Vytvo≈ôit `ui/screens/document/DocumentViewerScreen.kt`:**
  - PDF viewer (pou≈æ√≠t PdfBox rendering nebo WebView)
  - Markdown renderer (Markwon v TextView)
  - Plain text viewer (ScrollableText)
- [ ] **Vytvo≈ôit `ui/screens/document/DocumentViewerViewModel.kt`:**
  - Load document content
  - State: `document`, `currentPage` (pro PDF), `isLoading`
  - Actions: `loadDocument()`, `nextPage()`, `prevPage()`
- [ ] **Implementovat highlight matched chunks:**
  - Find chunk position v dokumentu
  - Scroll to matched section
  - Highlight background color
- [ ] **Navigation:**
  - Roz≈°√≠≈ôit `constants/Navigation.kt` o `DOCUMENT_VIEWER` route
  - Add to NavHost
- [ ] **Commit:** `‚ú® feat: Document viewer s PDF/MD/TXT support`

#### 3.4 Search Results Highlighting
- [ ] **Vytvo≈ôit `ui/components/HighlightedText.kt`:**
  ```kotlin
  @Composable
  fun HighlightedText(
      text: String,
      highlights: List<IntRange>,
      highlightColor: Color = MaterialTheme.colorScheme.primary.copy(alpha = 0.3f)
  )
  ```
- [ ] **Implementovat snippet extraction:**
  - Find best matching chunk
  - Extract ~200 chars around match
  - Add "..." elipsis
- [ ] **Roz≈°√≠≈ôit `DocumentResultCard`:**
  - Display highlighted snippet
  - Show relevance score (0-100%)
- [ ] **Commit:** `‚ú® feat: Search result snippet highlighting`

#### 3.5 Indexing Progress UI
- [ ] **Vytvo≈ôit `ui/components/DocumentIndexingBanner.kt`:**
  - Zobrazit kdy≈æ indexing bƒõ≈æ√≠
  - Progress bar + text "Indexov√°n√≠... (5/20)"
  - Cancel button
- [ ] **Integrovat do `MainActivity.kt`:**
  - Observe WorkManager state
  - Show/hide banner based on worker state
- [ ] **Commit:** `‚ú® feat: Document indexing progress UI`

---

### üß™ F√ÅZE 4: TESTING & OPTIMIZATION

#### 4.1 Unit Tests
- [ ] **Parser tests:**
  - Test v≈°echny parsery s real sample files
  - Test error handling (corrupted files)
- [ ] **Chunking tests:**
  - Test overlap correctness
  - Test token counting accuracy
  - Test edge cases
- [ ] **Embedding tests:**
  - Test batch processing
  - Test memory management
- [ ] **Repository tests:**
  - Test CRUD operations
  - Test search logic
  - Test index persistence
- [ ] **Coverage target:** 80%+ pro core logic
- [ ] **Commit:** `‚úÖ test: Unit tests pro document processing`

#### 4.2 Integration Tests
- [ ] **End-to-end indexing test:**
  - `androidTest/DocumentIndexingTest.kt`
  - Index sample PDF/MD/TXT
  - Verify embeddings saved correctly
  - Verify search returns expected results
- [ ] **Worker test:**
  - Test DocumentIndexWorker s WorkManager TestDriver
  - Verify notification shown
  - Verify progress updates
- [ ] **UI tests:**
  - Test settings screen interactions
  - Test search screen filtering
  - Test document viewer navigation
- [ ] **Commit:** `‚úÖ test: Integration tests pro document search`

#### 4.3 Performance Optimization
- [ ] **Benchmark chunking:**
  - Measure time pro 1000-page PDF
  - Optimize sentence splitting (use regex?)
- [ ] **Benchmark embedding extraction:**
  - Measure time per chunk
  - Tune batch size pro optimal throughput
  - Test FP16 vs FP32 (quality vs speed)
- [ ] **Benchmark search:**
  - Measure query time na 10k chunks
  - Profil cosine similarity (optimize loop?)
- [ ] **Memory profiling:**
  - Monitor peak memory usage bƒõhem indexov√°n√≠
  - Verify no memory leaks (LeakCanary)
- [ ] **Commit:** `‚ö° perf: Document processing optimizations`

#### 4.4 Error Handling & Edge Cases
- [ ] **Graceful degradation:**
  - Model not found ‚Üí show setup instructions
  - OOM during indexing ‚Üí reduce batch size
  - Corrupted document ‚Üí skip a log error
- [ ] **User feedback:**
  - Toast messages pro errors
  - Retry mechanism pro failed documents
  - Error log v Settings (show failed files)
- [ ] **Edge cases:**
  - Empty documents
  - Very large PDFs (1000+ pages)
  - Non-UTF8 text files
  - Scanned PDFs (no text layer)
- [ ] **Commit:** `üêõ fix: Error handling pro document indexing`

---

### üìö F√ÅZE 5: DOCUMENTATION & RELEASE

#### 5.1 Code Documentation
- [ ] **P≈ôidat KDoc comments:**
  - V≈°echny public API funkce
  - Complex algorithms (chunking, similarity)
- [ ] **Update `CLAUDE.md`:**
  - Document search architecture
  - File structure changes
  - Build commands (≈æ√°dn√© nov√©)
- [ ] **Vytvo≈ôit `docs/DOCUMENT_SEARCH.md`:**
  - User guide (jak nastavit)
  - Technical overview
  - Troubleshooting
- [ ] **Commit:** `üìù docs: Document search documentation`

#### 5.2 User Guide
- [ ] **In-app help dialog:**
  - "Jak pou≈æ√≠vat vyhled√°v√°n√≠ v dokumentech?"
  - Screenshot/tutorial steps
- [ ] **Settings tooltips:**
  - Info icon u ka≈æd√©ho nastaven√≠
  - Explain co dƒõl√°
- [ ] **Commit:** `üìù docs: In-app help pro document search`

#### 5.3 Migration & Backward Compatibility
- [ ] **Test upgrade z v1.1.3:**
  - Verify database migration runs
  - Verify existing image embeddings funguj√≠
  - No crashes on first launch
- [ ] **Opt-in feature toggle:**
  - Default: disabled (pro existuj√≠c√≠ users)
  - Show "New Feature" badge v Settings
- [ ] **Commit:** `‚ôªÔ∏è refactor: Backward compatible document search`

#### 5.4 Release Preparation
- [ ] **Update `app/build.gradle.kts`:**
  - Bump version: `1.2.0`
  - Update versionCode
- [ ] **Update changelog:**
  - Vytvo≈ôit `CHANGELOG.md` entry pro v1.2.0
  - List all new features
- [ ] **F-Droid metadata:**
  - Update `metadata/en-US/changelogs/XX.txt`
  - Add feature description
- [ ] **Test release build:**
  - `./gradlew assembleRelease`
  - Verify ProGuard rules (≈æ√°dn√© crashes)
  - Test na real device
- [ ] **Commit:** `üöÄ release: SmartScan v1.2.0 - Document Search`

---

### üìä BONUS: ADVANCED FEATURES (Optional)

#### Bonus 1: OCR Support (pro scanned PDFs)
- [ ] **Integrate Tesseract-Android:**
  - `implementation("com.rmtheis:tess-two:9.1.0")`
- [ ] **Detect scanned PDFs:**
  - Check if text extraction returns empty
  - Render PDF pages to images
  - Run OCR na ka≈ædou str√°nku
- [ ] **Commit:** `‚ú® feat: OCR support pro scanned PDFs`

#### Bonus 2: Multilingual Support
- [ ] **Download multilingual model:**
  - `paraphrase-multilingual-MiniLM-L12-v2` (118 MB)
- [ ] **Language detection:**
  - Use `lingua-kotlin` nebo `fasttext-langdetect`
  - Route to appropriate model
- [ ] **Commit:** `‚ú® feat: Multilingual document search`

#### Bonus 3: FAISS Integration (pro scale)
- [ ] **Compile FAISS for Android:**
  - NDK build script
  - Wrapper JNI interface
- [ ] **Replace brute-force search:**
  - Use HNSW index
  - 10-100x faster pro large indexes
- [ ] **Commit:** `‚ö° perf: FAISS ANN search integration`

#### Bonus 4: Document Auto-Tagging
- [ ] **Vytvo≈ôit `DocumentTagger.kt`:**
  - Analyze document content (keywords, topics)
  - Generate tags using text embeddings
  - Cluster similar documents
- [ ] **UI:**
  - Show tags v document cards
  - Filter by tag
- [ ] **Commit:** `‚ú® feat: Automatic document tagging`

---

## üìà PROGRESS TRACKING

### Milestones:
- [ ] **M1:** Infrastructure ready (F√°ze 1 complete) - ~1 t√Ωden
- [ ] **M2:** Processing pipeline working (F√°ze 2 complete) - ~2 t√Ωdny
- [ ] **M3:** UI integrated (F√°ze 3 complete) - ~1 t√Ωden
- [ ] **M4:** Tested & optimized (F√°ze 4 complete) - ~1 t√Ωden
- [ ] **M5:** Release ready (F√°ze 5 complete) - ~3 dny

**Estimated total:** ~5-6 t√Ωdn≈Ø (part-time development)

### Risks:
- ‚ö†Ô∏è **Model size:** Users may complain o +27 MB download
- ‚ö†Ô∏è **Performance:** Indexing m≈Ø≈æe b√Ωt pomal√© na low-end devices
- ‚ö†Ô∏è **English-only:** Multilingual support vy≈æaduje vƒõt≈°√≠ model
- ‚ö†Ô∏è **F-Droid build:** Reproducibility s native libs (tokenizer)

### Dependencies:
- üî¥ **Critical path:** F√°ze 1 ‚Üí F√°ze 2 ‚Üí F√°ze 3 (mus√≠ b√Ωt v po≈ôad√≠)
- üü° **Parallel work:** Testing (F√°ze 4) m≈Ø≈æe bƒõ≈æet paralelnƒõ s UI (F√°ze 3)
- üü¢ **Bonus features:** Nez√°visl√©, lze p≈ôidat kdykoliv pozdƒõji

---

## üîç Zji≈°tƒõn√≠ o SmartScan SDK

### Souƒçasn√Ω stav SDK:
- ‚ùå **Nepodporuje text embeddings** - pouze image embeddings
- ‚úÖ **CLIP model** - dual-modal (text-to-image search), ale negeneruje pure text embeddings
- ‚ö†Ô∏è **TEXT_ENCODER model typ existuje** v `constants/Models.kt:10` - infrastruktura je p≈ôipraven√°
- **Z√°vƒõr:** Mus√≠me p≈ôidat separ√°tn√≠ text embedding solution

### Podporovan√© modely v SmartScan SDK:
```kotlin
// constants/Models.kt
SmartScanModelType.FACE           // Facial recognition
SmartScanModelType.OBJECTS        // Object detection
SmartScanModelType.IMAGE_ENCODER  // Image embeddings (CLIP)
SmartScanModelType.TEXT_ENCODER   // Text encoder (CLIP, pro text-to-image)
```

---

## ‚úÖ Technick√° proveditelnost

| Komponenta | ≈òe≈°en√≠ | Kompatibilita | Velikost |
|-----------|---------|---------------|----------|
| **Text Embeddings** | all-MiniLM-L6-v2 + ONNX Runtime | ‚úÖ Kompatibiln√≠ s existuj√≠c√≠m stackem | 22 MB |
| **PDF Parsing** | PdfBox-Android (TomRoush fork) | ‚úÖ Pure Java, F-Droid friendly | ~15 MB |
| **Markdown Parsing** | CommonMark-Java / Markwon | ‚úÖ Zero dependencies | ~1 MB |
| **Indexing** | File-based (konzistentn√≠ s images) | ‚úÖ Stejn√Ω pattern jako v1.1.3 | N/A |
| **Search** | Cosine similarity | ‚úÖ Ji≈æ implementov√°no pro images | N/A |

---

## üéØ Doporuƒçen√© ≈ôe≈°en√≠

### Architektura:

```
Text Documents (PDF/MD/TXT)
        ‚Üì
   Parser Layer
   ‚îú‚îÄ‚îÄ PdfBox-Android (PDF)
   ‚îú‚îÄ‚îÄ CommonMark-Java (MD)
   ‚îî‚îÄ‚îÄ File.readText() (TXT)
        ‚Üì
   Chunking Service
   (512 tokens, 15% overlap)
        ‚Üì
   all-MiniLM-L6-v2 ONNX Model
        ‚Üì
   384-dim Embeddings
        ‚Üì
   File-based Index (JSON)
        ‚Üì
   Cosine Similarity Search
```

### Knihovny k p≈ôid√°n√≠:

```gradle
// build.gradle.kts
dependencies {
    // Text embeddings - Sentence Transformers pro Android
    implementation("com.github.shubham0204:Sentence-Embeddings-Android:1.x.x")

    // PDF parsing - Apache PDFBox fork pro Android
    implementation("com.tom-roush:pdfbox-android:2.0.27.0")

    // Markdown parsing
    implementation("io.noties.markwon:core:4.6.2")
    // nebo
    implementation("org.commonmark:commonmark:0.21.0")
}
```

---

## üí° Implementaƒçn√≠ pl√°n (high-level)

### **F√°ze 1: Infrastruktura (Foundation)**
1. ‚úÖ P≈ôidat text embedding dependencies do `build.gradle.kts`
2. ‚úÖ St√°hnout/integrovat all-MiniLM-L6-v2 ONNX model
3. ‚úÖ Roz≈°√≠≈ôit `SmartScanModelType` enum o `TEXT_DOCUMENT_ENCODER`
4. ‚úÖ Vytvo≈ôit data model:
   - `TextDocument` entity (Room DB metadata)
   - `DocumentChunk` data class
   - `DocumentEmbeddingIndex` (file-based storage)

### **F√°ze 2: Document Processing**
5. ‚úÖ Implementovat parsery:
   - `PdfParser` (PdfBox-Android)
   - `MarkdownParser` (CommonMark-Java)
   - `TxtParser` (plain text)
6. ‚úÖ Document chunking service:
   - Semantic chunking (split na vƒõty ‚Üí group)
   - 512 tokens per chunk, 15% overlap
   - Metadata tracking (file path, page, offset)
7. ‚úÖ Text embedding extraction:
   - `TextEmbeddingExtractor` wrapper
   - Batch processing (10 chunks at once)
   - Memory management
8. ‚úÖ Background worker:
   - `DocumentIndexWorker` (WorkManager)
   - Foreground service s notifikac√≠
   - Progress tracking

### **F√°ze 3: Search & UI**
9. ‚úÖ Roz≈°√≠≈ôit search screen:
   - Unified search (images + documents)
   - Document result cards
   - Relevance scoring (cosine similarity)
10. ‚úÖ Document viewer UI:
    - PDF viewer (fragment)
    - Markdown renderer (Markwon)
    - Highlight matched chunks
11. ‚úÖ Settings:
    - Document indexing preferences
    - File type filters
    - Auto-refresh intervals

---

## üîß Technick√© detaily

### 1. Text Embedding Model

**Doporuƒçen√Ω model: all-MiniLM-L6-v2**

- **Zdroj:** [HuggingFace - onnx-models/all-MiniLM-L6-v2-onnx](https://huggingface.co/onnx-models/all-MiniLM-L6-v2-onnx)
- **Velikost:** 22 MB (ONNX), 5 MB (tokenizer native lib)
- **Embedding dimension:** 384
- **Performance:** ~60ms per chunk (512 tokens) na mid-range Android
- **Jazyk:** English (pro multilingual pou≈æ√≠t `paraphrase-multilingual-MiniLM-L12-v2`)

**Implementace (pseudo-code):**
```kotlin
// Inicializace
val sentenceEmbedding = SentenceEmbedding(
    modelFile = context.filesDir.resolve("models/text_encoder.onnx"),
    tokenizerFile = context.filesDir.resolve("models/tokenizer.json"),
    useTokenTypeIds = true,
    outputTensorName = "last_hidden_state",
    useFP16 = true,      // 2x men≈°√≠ storage, <1% quality loss
    useXNNPack = true    // CPU optimization pro ARM
)

// Z√≠sk√°n√≠ embeddings
val embedding: FloatArray = sentenceEmbedding.encode("V√°≈° text")
// Output: [384] float array
```

**Alternativn√≠ modely:**
- **snowflake-arctic-embed-s:** Vy≈°≈°√≠ kvalita, pomalej≈°√≠ (~100 MB)
- **bge-small-en:** Alternativa k MiniLM (33 MB)
- **model2vec:** Ultra-lightweight (5 MB), ni≈æ≈°√≠ kvalita

---

### 2. PDF Parsing

**Knihovna: PdfBox-Android**

- **Repo:** [TomRoush/PdfBox-Android](https://github.com/TomRoush/PdfBox-Android)
- **Licence:** Apache 2.0 (F-Droid compatible)
- **API:** PDDocument, PDFTextStripper

**Best practices:**
```kotlin
// Memory-efficient page-by-page extraction
fun extractPdfText(uri: Uri): List<String> {
    val inputStream = contentResolver.openInputStream(uri)
    val document = PDDocument.load(inputStream)
    val stripper = PDFTextStripper()
    val pages = mutableListOf<String>()

    for (page in 1..document.numberOfPages) {
        stripper.startPage = page
        stripper.endPage = page
        val text = stripper.getText(document)
        pages.add(text)
    }

    document.close()
    return pages
}
```

**Performance pozn√°mky:**
- ‚ö†Ô∏è Kotlin vs Java: ~2s rozd√≠l v testu (PDFBox 2.0.12)
- ‚úÖ Extrahuj text po str√°nk√°ch, ne cel√Ω dokument najednou
- ‚úÖ Close PDDocument po pou≈æit√≠ (nen√≠ thread-safe)

**Alternativy:**
- **iText:** Komerƒçn√≠ licence (AGPL pro open-source)
- **PdfiumAndroid:** Nativn√≠, rychlej≈°√≠, slo≈æitƒõj≈°√≠ API

---

### 3. Markdown Parsing

**Doporuƒçen√© knihovny:**

**Option A: Markwon** (Android-native)
- **Repo:** [noties/Markwon](https://github.com/noties/Markwon)
- **Features:** CommonMark spec, HTML support, syntax highlight
- **API Level:** Min 19
- **Use case:** Rendering + text extraction

**Option B: CommonMark-Java** (standalone)
- **Repo:** [commonmark/commonmark-java](https://github.com/commonmark/commonmark-java)
- **Performance:** 10-20x rychlej≈°√≠ ne≈æ pegdown
- **API:** AST-based, extensible
- **Use case:** Pure text extraction

**Implementace (CommonMark-Java):**
```kotlin
fun extractMarkdownText(markdown: String): String {
    val parser = Parser.builder().build()
    val document = parser.parse(markdown)
    val textBuilder = StringBuilder()

    document.accept(object : AbstractVisitor() {
        override fun visit(text: Text) {
            textBuilder.append(text.literal).append(" ")
        }
        override fun visit(heading: Heading) {
            // Preserve headings for semantic structure
            textBuilder.append("\n\n")
            visitChildren(heading)
            textBuilder.append("\n\n")
        }
    })

    return textBuilder.toString()
}
```

**Plain TXT:**
```kotlin
fun extractPlainText(file: File): String {
    return file.readText(Charset.forName("UTF-8"))
}
```

---

### 4. Chunking Strategie

**Doporuƒçen√° metoda: Semantic Chunking**

**Parametry:**
- **Chunk size:** 512 tokens (optimal pro all-MiniLM-L6-v2)
- **Overlap:** 15-20% (p≈ôedejde boundary loss)
- **Granularita:** Split na vƒõty ‚Üí group po 3-5 vƒõt√°ch

**Proƒç overlap?**
- Informace roz≈ô√≠znut√° mezi chunky by byla ztracena
- 15% overlap = posledn√≠ ~75 token≈Ø z p≈ôedchoz√≠ho chunku

**Implementace (pseudo-code):**
```kotlin
data class DocumentChunk(
    val id: String,              // "doc1_chunk0"
    val text: String,            // P≈Øvodn√≠ text
    val embedding: FloatArray,   // 384-dim embedding
    val metadata: ChunkMetadata
)

data class ChunkMetadata(
    val filePath: String,
    val pageNumber: Int?,        // Pro PDF
    val charOffset: Int,         // Start position v dokumentu
    val chunkIndex: Int
)

fun chunkDocument(
    text: String,
    maxTokens: Int = 512,
    overlapPercent: Float = 0.15f
): List<DocumentChunk> {
    val sentences = text.splitToSentences()  // NLTK-style
    val chunks = mutableListOf<DocumentChunk>()

    var currentChunk = StringBuilder()
    var currentTokens = 0
    var charOffset = 0

    for (sentence in sentences) {
        val sentenceTokens = tokenizer.encode(sentence).size

        if (currentTokens + sentenceTokens > maxTokens) {
            // Save current chunk
            chunks.add(
                DocumentChunk(
                    id = "doc_chunk${chunks.size}",
                    text = currentChunk.toString(),
                    embedding = embedModel.encode(currentChunk.toString()),
                    metadata = ChunkMetadata(
                        filePath = filePath,
                        pageNumber = currentPage,
                        charOffset = charOffset,
                        chunkIndex = chunks.size
                    )
                )
            )

            // Apply overlap: keep last N tokens
            val overlapSize = (maxTokens * overlapPercent).toInt()
            val overlapText = getLastNTokens(currentChunk.toString(), overlapSize)
            currentChunk = StringBuilder(overlapText)
            currentTokens = overlapSize
        }

        currentChunk.append(sentence).append(" ")
        currentTokens += sentenceTokens
    }

    // Save last chunk
    if (currentChunk.isNotEmpty()) {
        chunks.add(createChunk(currentChunk.toString()))
    }

    return chunks
}
```

**Chunking guidelines podle typu:**

| Document Type | Chunk Size | Overlap | Split Strategy |
|--------------|-----------|---------|----------------|
| PDF (technical) | 512-1024 tokens | 15-25% | Str√°nky ‚Üí odstavce ‚Üí vƒõty |
| Markdown | 256-512 tokens | 10-20% | Headings ‚Üí odstavce ‚Üí vƒõty |
| Plain TXT | 256-512 tokens | 10-20% | Odstavce ‚Üí vƒõty |
| Code snippets | 100-300 tokens | 20% | Function/class scope |

---

### 5. Indexing & Storage

**File-based index (konzistentn√≠ s image embeddings od v1.1.3):**

```json
{
  "version": "1.0.0",
  "documentCount": 42,
  "chunks": [
    {
      "id": "doc1_chunk0",
      "text": "This is the first chunk of document 1...",
      "embedding": [0.123, -0.456, 0.789, ...],  // 384 floats
      "metadata": {
        "filePath": "/storage/emulated/0/Documents/report.pdf",
        "fileName": "report.pdf",
        "fileType": "pdf",
        "pageNumber": 1,
        "charOffset": 0,
        "chunkIndex": 0,
        "timestamp": 1704067200000
      }
    }
  ]
}
```

**Storage location:**
```
context.filesDir/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ text_encoder.onnx       (22 MB)
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.json          (5 MB)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ indexes/
‚îÇ   ‚îú‚îÄ‚îÄ documents_index.json    (embeddings + metadata)
‚îÇ   ‚îî‚îÄ‚îÄ documents_metadata.db   (Room DB - scan history, jobs)
```

**Room DB schema (pouze metadata):**
```kotlin
@Entity(tableName = "text_documents")
data class TextDocument(
    @PrimaryKey val id: String,
    val filePath: String,
    val fileName: String,
    val fileType: String,      // "pdf", "md", "txt"
    val fileSize: Long,
    val chunkCount: Int,
    val indexedAt: Long,
    val lastModified: Long
)

@Entity(tableName = "document_scans")
data class DocumentScan(
    @PrimaryKey(autoGenerate = true) val id: Long = 0,
    val scanDate: Long,
    val documentsFound: Int,
    val documentsIndexed: Int,
    val duration: Long
)
```

---

### 6. Search Implementation

**Cosine similarity (ji≈æ existuje pro images):**
```kotlin
fun cosineSimilarity(a: FloatArray, b: FloatArray): Float {
    require(a.size == b.size) { "Vectors must have same dimension" }

    var dotProduct = 0.0
    var magnitudeA = 0.0
    var magnitudeB = 0.0

    for (i in a.indices) {
        dotProduct += a[i] * b[i]
        magnitudeA += a[i] * a[i]
        magnitudeB += b[i] * b[i]
    }

    magnitudeA = sqrt(magnitudeA)
    magnitudeB = sqrt(magnitudeB)

    return (dotProduct / (magnitudeA * magnitudeB)).toFloat()
}
```

**Search pipeline:**
```kotlin
suspend fun searchDocuments(
    query: String,
    topK: Int = 10,
    minSimilarity: Float = 0.5f
): List<SearchResult> = withContext(Dispatchers.Default) {
    // 1. Generate query embedding
    val queryEmbedding = textEmbedModel.encode(query)

    // 2. Load document index
    val index = loadDocumentIndex()

    // 3. Compute similarities
    val results = index.chunks
        .asSequence()
        .map { chunk ->
            SearchResult(
                chunk = chunk,
                similarity = cosineSimilarity(queryEmbedding, chunk.embedding)
            )
        }
        .filter { it.similarity >= minSimilarity }
        .sortedByDescending { it.similarity }
        .take(topK)
        .toList()

    return@withContext results
}
```

**Unified search (images + documents):**
```kotlin
data class UnifiedSearchResult(
    val type: ResultType,      // IMAGE, DOCUMENT
    val score: Float,
    val data: Any              // ImageResult or DocumentResult
)

suspend fun unifiedSearch(query: String): List<UnifiedSearchResult> {
    // Parallel search
    val imageResults = async { searchImages(query) }
    val docResults = async { searchDocuments(query) }

    // Merge & sort by relevance
    return (imageResults.await() + docResults.await())
        .sortedByDescending { it.score }
}
```

---

## üìä Performance & Optimizace

### Memory Management

**Model loading:**
```kotlin
// Lazy initialization
private val textEmbedModel: SentenceEmbedding by lazy {
    SentenceEmbedding(
        modelFile = modelPath,
        tokenizerFile = tokenizerPath,
        useFP16 = true,        // 2x men≈°√≠ storage
        useXNNPack = true      // CPU optimization
    )
}

// Clear po pou≈æit√≠
fun cleanup() {
    textEmbedModel.close()
}
```

**Batch processing:**
```kotlin
// Process documents in batches
suspend fun indexDocuments(documents: List<File>) {
    val batchSize = 10
    documents.chunked(batchSize).forEach { batch ->
        batch.forEach { doc ->
            val chunks = parseAndChunk(doc)
            chunks.chunked(10).forEach { chunkBatch ->
                // Embed 10 chunks at once
                val embeddings = textEmbedModel.encodeBatch(
                    chunkBatch.map { it.text }
                )
                saveEmbeddings(chunkBatch, embeddings)
            }
        }

        // Clear intermediate buffers
        System.gc()
    }
}
```

### Inference Optimizations

**1. FP16 (Half-precision):**
- Storage: 2x men≈°√≠
- Quality loss: <1%
- Enable: `useFP16 = true`

**2. XNNPack (CPU optimization):**
- Speedup: 1.4-3x na ARM CPUs
- Enable: `useXNNPack = true`

**3. Quantization (INT8):**
- Storage: 4x men≈°√≠
- Quality loss: ~5%
- Vy≈æaduje custom ONNX model

**Benchmark (Samsung M13, 4GB RAM):**
```
Model: all-MiniLM-L6-v2
Input: 128 tokens

Baseline (FP32):         ~90ms
FP16 + XNNPack:         ~60ms
INT8 quantized:         ~45ms
```

---

## ‚ö†Ô∏è D≈Øle≈æit√© pozn√°mky

### Model Size Impact

| Komponenta | Velikost | Pozn√°mka |
|-----------|----------|----------|
| St√°vaj√≠c√≠ CLIP (IMAGE_ENCODER) | ~75 MB | Ji≈æ v projektu |
| St√°vaj√≠c√≠ CLIP (TEXT_ENCODER) | ~75 MB | Ji≈æ v projektu |
| **Nov√Ω text model** | **+22 MB** | all-MiniLM-L6-v2 |
| Tokenizer (Rust native lib) | +5 MB | HuggingFace tokenizers |
| **Celkem** | **~177 MB** | Akceptovateln√© pro on-device |

### Performance Expectations

**Indexov√°n√≠ (1000-page PDF):**
- Parsing: ~30s (PdfBox-Android)
- Chunking: ~5s (512 tokens/chunk ‚Üí ~2000 chunks)
- Embedding extraction: ~2 min (60ms √ó 2000 chunks)
- **Total:** ~2.5 min (background WorkManager job)

**Search (10k chunks index):**
- Query embedding: ~60ms
- Similarity computation: ~50ms (brute-force)
- **Total:** ~110ms per query

**Optimalizace pro vƒõt≈°√≠ scale:**
- FAISS index (ANN search): ~5-10ms pro 100k chunks
- Vy≈æaduje native compile (slo≈æitƒõj≈°√≠ F-Droid build)

### F-Droid Compatibility

| Knihovna | Licence | F-Droid | Pozn√°mka |
|----------|---------|---------|----------|
| Sentence-Embeddings-Android | Apache 2.0 | ‚úÖ | Open-source, reprodukovateln√Ω build |
| PdfBox-Android | Apache 2.0 | ‚úÖ | Pure Java, zero native deps |
| CommonMark-Java | BSD 2-Clause | ‚úÖ | Zero dependencies |
| ONNX Runtime | MIT | ‚úÖ | Maven Central artifacts |
| HuggingFace Tokenizers | Apache 2.0 | ‚úÖ | Rust ‚Üí .so prebuilt |

**‚ö†Ô∏è Pozn√°mka k FAISS:**
- ‚ùå Vy≈æaduje NDK build (native C++)
- Komplikuje F-Droid reproducible builds
- Doporuƒçen√≠: Start s brute-force, p≈ôidej FAISS pozdƒõji pokud nutn√©

---

## üîó Zdroje & Reference

### Implementace

**Text Embeddings:**
- [Sentence-Embeddings-Android GitHub](https://github.com/shubham0204/Sentence-Embeddings-Android)
- [ProAndroidDev ƒçl√°nek](https://proandroiddev.com/from-python-to-android-hf-sentence-transformers-embeddings-1ecea0ce94d8)
- [ONNX Runtime Android](https://onnxruntime.ai/docs/get-started/with-java.html)

**PDF Parsing:**
- [PdfBox-Android GitHub](https://github.com/TomRoush/PdfBox-Android)
- [Apache PDFBox Documentation](https://pdfbox.apache.org/)

**Markdown Parsing:**
- [Markwon GitHub](https://github.com/noties/Markwon)
- [CommonMark-Java GitHub](https://github.com/commonmark/commonmark-java)
- [CommonMark Spec](https://commonmark.org/)

**ML Models:**
- [all-MiniLM-L6-v2 (ONNX)](https://huggingface.co/onnx-models/all-MiniLM-L6-v2-onnx)
- [Sentence Transformers Hub](https://huggingface.co/sentence-transformers)
- [ONNX Model Zoo](https://github.com/onnx/models)

### Best Practices

**Chunking Strategies:**
- [Pinecone - Chunking Guide](https://www.pinecone.io/learn/chunking-strategies/)
- [Stack Overflow - RAG Chunking](https://stackoverflow.blog/2024/12/27/breaking-up-is-hard-to-do-chunking-in-rag-applications/)
- [Chroma Research - Evaluating Chunking](https://research.trychroma.com/evaluating-chunking)
- [Late Chunking Paper (2024)](https://arxiv.org/html/2409.04701v3)

**Semantic Search:**
- [OpenAI - Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [Google - Semantic Search Best Practices](https://cloud.google.com/blog/topics/developers-practitioners/meet-ais-multitool-vector-embeddings)

---

## üöÄ Dal≈°√≠ kroky

### Mo≈ænosti pokraƒçov√°n√≠:

**A) Detailn√≠ implementaƒçn√≠ pl√°n**
- Konkr√©tn√≠ TODO items s file paths
- Code snippets pro ka≈ædou komponentu
- Testovac√≠ strategie

**B) Datab√°zov√Ω schema design**
- Room entities + DAOs
- Migration strategy z v1.1.3
- Index file format

**C) Proof-of-concept**
- Integrace Sentence-Embeddings-Android
- Minim√°ln√≠ PDF parsing demo
- Search prototype

**D) Architecture review**
- Dopad na existuj√≠c√≠ codebase
- Refactoring pot≈ôeby
- Backward compatibility

---

**Datum anal√Ωzy:** 2025-10-27
**SmartScan verze:** v1.1.3
**Analyzov√°no pro:** mist≈ôe Jardo

---

## üìù Pozn√°mky k implementaci

### Edge Cases

**1. Multi-language documents:**
- all-MiniLM-L6-v2 = English only
- Pro multilingual: `paraphrase-multilingual-MiniLM-L12-v2` (118 MB)
- Detect language ‚Üí use appropriate model

**2. PDF s obr√°zky/tabulkami:**
- PdfBox extracts text v reading order
- Obr√°zky/tabulky = mezery v textu
- Mo≈ænost: OCR integration (Tesseract-Android)

**3. Markdown code blocks:**
- Skip nebo preserve jako single chunk?
- Syntax highlighting metadata
- Language detection

**4. Large documents:**
- Streaming parsing (don't load entire file)
- Progressive indexing (save chunks incrementally)
- Memory pressure monitoring

### Testing Strategy

**Unit tests:**
```kotlin
// Chunking logic
@Test
fun `test semantic chunking with overlap`() { ... }

// Similarity computation
@Test
fun `test cosine similarity calculation`() { ... }

// Parser integration
@Test
fun `test PDF text extraction`() { ... }
```

**Integration tests:**
```kotlin
// End-to-end indexing
@Test
fun `test document indexing pipeline`() { ... }

// Search accuracy
@Test
fun `test search returns relevant results`() { ... }
```

**Performance tests:**
```kotlin
// Benchmark chunking
@Test
fun `benchmark chunk 1000-page PDF`() { ... }

// Benchmark search
@Test
fun `benchmark search in 10k chunks`() { ... }
```

### Migration Path

**Pro existuj√≠c√≠ SmartScan users:**

1. **Opt-in feature** (Settings toggle)
2. **Background migration** (scan documents on first launch)
3. **Progress notification** (jako u image indexing)
4. **Fallback** (graceful degradation pokud modely chyb√≠)

---

## ‚úÖ Z√°vƒõr

**SmartScan m≈Ø≈æe b√Ωt roz≈°√≠≈ôen o s√©mantick√© vyhled√°v√°n√≠ v dokumentech:**

- ‚úÖ Technicky provediteln√© (100%)
- ‚úÖ F-Droid compatible stack
- ‚úÖ Konzistentn√≠ s existuj√≠c√≠ architekturou
- ‚úÖ Reasonable performance (on-device)
- ‚úÖ Moderate storage impact (+27 MB)

**Doporuƒçen√≠:**
- Start s all-MiniLM-L6-v2 (optimal kvalita/rychlost)
- File-based embeddings storage (konzistence)
- Background WorkManager indexing
- Opt-in feature v Settings

**Rizika:**
- Model download size (+27 MB)
- Indexing time (2-3 min per 1000 pages)
- English-only support (initial version)
- Memory usage (batch processing kritick√Ω)

**Celkov√© hodnocen√≠:** üü¢ **Doporuƒçeno k implementaci**
